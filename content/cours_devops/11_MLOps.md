---
title: "MLOps"
description: "Ma√Ætriser l‚Äôensemble du cycle de vie des projets de machine learning, de la gestion des donn√©es au d√©ploiement en production, en appliquant des pratiques robustes inspir√©es du DevOps."
category: "cours-devops"
---

# MLOps

# Chapitre 1 ‚Äî Introduction au MLOps

## Qu'est-ce que le MLOps ?

Le MLOps, pour **Machine Learning Operations**, est un ensemble de pratiques visant √† automatiser, fiabiliser et industrialiser le cycle de vie des mod√®les de machine learning. Inspir√© du DevOps, il s‚Äôadapte aux sp√©cificit√©s des projets ML, qui sont plus sensibles √† la variabilit√© des donn√©es, au risque de d√©rive des performances dans le temps, et √† la non-d√©terminisme des r√©sultats.

Le MLOps ne concerne pas seulement le d√©ploiement des mod√®les, mais englobe toute la cha√Æne : ingestion des donn√©es, exp√©rimentation, entra√Ænement, validation, packaging, mise en production, surveillance, et mise √† jour continue.

Il vise √† r√©pondre √† des enjeux concrets :
- Reproductibilit√© des exp√©riences
- Collaboration fluide entre data scientists, ing√©nieurs ML, DevOps
- D√©ploiement rapide, fiable, tra√ßable
- Suivi des performances en production

---

## Diff√©rences entre DevOps et MLOps

Bien que le MLOps s‚Äôinspire du DevOps, il s‚Äôen distingue sur plusieurs points fondamentaux :

| √âl√©ment                     | DevOps                         | MLOps                                              |
|----------------------------|--------------------------------|-----------------------------------------------------|
| Entr√©e principale          | Code source                    | Code + donn√©es + hyperparam√®tres                   |
| R√©sultat attendu           | Application d√©terministe       | Mod√®le entra√Æn√© avec performance statistique       |
| Tests                      | Fonctionnels/unitaires         | Statistiques, validit√©, robustesse du mod√®le       |
| CI/CD                      | Build et d√©ploiement logiciel  | Entra√Ænement, packaging, d√©ploiement de mod√®le     |
| Monitoring                 | Logs, erreurs, uptime          | Pr√©cision, d√©rive, m√©triques m√©tier                |
| Reproductibilit√©           | Compilation identique          | D√©pend aussi de la qualit√© et version des donn√©es  |

Le MLOps impose donc des outils et workflows sp√©cifiques pour :
- versionner les donn√©es et les mod√®les ;
- suivre les exp√©riences d‚Äôentra√Ænement ;
- d√©clencher des retrainings ;
- monitorer les m√©triques m√©tier en production.

---

## Cycle de vie d‚Äôun projet ML

Le MLOps structure un cycle de vie complet du machine learning, souvent it√©ratif :

1. **Collecte des donn√©es**  
   - Acc√®s aux sources de donn√©es (bases SQL, fichiers, APIs, etc.)
   - Extraction, nettoyage, et pr√©traitement

2. **Exploration & analyse des donn√©es**  
   - Visualisations, corr√©lations, d√©tection d‚Äôanomalies
   - Compr√©hension du contexte m√©tier

3. **Exp√©rimentation & entra√Ænement**  
   - S√©lection de mod√®les, tuning d‚Äôhyperparam√®tres
   - Entra√Ænement local, sur serveur ou en cloud

4. **Validation**  
   - √âvaluation sur jeux de tests
   - Analyse des m√©triques : accuracy, F1-score, ROC AUC, etc.

5. **Packaging du mod√®le**  
   - S√©rialisation (Pickle, ONNX, SavedModel)
   - Conteneurisation (Docker)

6. **D√©ploiement**  
   - En tant qu‚ÄôAPI (FastAPI, Flask)
   - Dans un orchestrateur (Kubernetes, SageMaker)

7. **Monitoring & maintenance**  
   - Suivi de performance dans le temps
   - D√©tection de d√©rive
   - D√©clenchement de retrainings automatiques si n√©cessaire

Ce cycle de vie est au c≈ìur du MLOps : il doit √™tre reproductible, automatis√© et tra√ßable.

---

## R√¥les impliqu√©s

Le MLOps repose sur la collaboration entre plusieurs profils aux comp√©tences compl√©mentaires :

- **Data Scientist**  
  Con√ßoit les mod√®les, les exp√©rimente, les valide sur des jeux de tests.

- **ML Engineer**  
  Impl√©mente les mod√®les de fa√ßon performante et scalable ; optimise les ressources.

- **MLOps Engineer**  
  Met en place les pipelines d‚Äôentra√Ænement, de test, de d√©ploiement, de monitoring. Automatise l‚Äôensemble du cycle de vie.

- **Data Engineer**  
  Met √† disposition les donn√©es n√©cessaires, construit les pipelines d‚Äôingestion et de transformation.

- **Software Engineer**  
  Int√®gre les mod√®les dans les applications et plateformes produits.

- **Product Owner / M√©tier**  
  D√©finit les objectifs m√©tiers, valide la pertinence des mod√®les, suit les KPIs en production.

---

## Outils et plateformes populaires

Les outils du MLOps couvrent diff√©rents domaines du cycle de vie :

### Versionnage
- **Git** (code source)
- **DVC**, **LakeFS** (donn√©es et artefacts)

### Suivi d‚Äôexp√©rimentations
- **MLflow**
- **Weights & Biases**
- **Neptune.ai**

### Orchestration de pipelines
- **Airflow**
- **Kubeflow Pipelines**
- **SageMaker Pipelines**

### Packaging et serving
- **Docker**
- **TensorFlow Serving**
- **TorchServe**
- **MLServer**

### CI/CD
- **GitHub Actions**
- **GitLab CI**
- **Argo Workflows**

### Monitoring en production
- **Evidently**
- **Prometheus + Grafana**
- **Seldon Core**

### Feature Stores
- **Feast**
- **Tecton**

Ces outils peuvent √™tre combin√©s dans des **stacks MLOps** coh√©rentes, selon les besoins et les ressources de l‚Äô√©quipe.

## Structure typique d‚Äôun repo MLOps

```
project_name/
‚îú‚îÄ‚îÄ data/                  # Donn√©es brutes, transform√©es (via DVC ou symlink)
‚îú‚îÄ‚îÄ notebooks/             # Explorations, prototypage
‚îú‚îÄ‚îÄ src/                   # Code source : preprocessing, entra√Ænement, √©valuation
‚îÇ   ‚îú‚îÄ‚îÄ data/              # Scripts d'ingestion et de preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ features/          # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ models/            # D√©finition, entra√Ænement et sauvegarde des mod√®les
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Fonctions utilitaires
‚îú‚îÄ‚îÄ pipelines/             # Pipelines MLflow, Prefect, Airflow, etc.
‚îú‚îÄ‚îÄ tests/                 # Tests unitaires et fonctionnels
‚îú‚îÄ‚îÄ dvc.yaml               # D√©finition des pipelines de donn√©es (si DVC utilis√©)
‚îú‚îÄ‚îÄ requirements.txt       # D√©pendances du projet
‚îú‚îÄ‚îÄ Dockerfile             # Containerisation du projet
‚îî‚îÄ‚îÄ README.md              # Description et instructions
```

---

## Exemple de pipeline CI/CD avec GitHub Actions + DVC + MLflow

```yaml
name: mlops-pipeline

on:
  push:
    branches: [ main ]

jobs:
  train-and-track:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install dvc[gs] mlflow

    - name: Pull data with DVC
      run: dvc pull -r myremote

    - name: Train and log model
      run: python src/models/train.py

    - name: Push model to registry
      run: mlflow register-model -m ./mlruns -n my-model-name
```

---

## Matrice de choix des outils MLOps selon le contexte

| Besoin                        | Open-source              | Cloud provider                      |
| ----------------------------- | ------------------------ | ----------------------------------- |
| Versionnage donn√©es + mod√®les | DVC + Git                | SageMaker + S3, Vertex AI + GCS     |
| Orchestration de pipelines    | Airflow, Prefect, Flyte  | SageMaker Pipelines, Azure ML       |
| Suivi des exp√©rimentations    | MLflow, W\&B, Neptune.ai | SageMaker Experiments, Vertex       |
| D√©ploiement API mod√®le        | FastAPI + Docker + K8s   | SageMaker Endpoint, Azure Endpoint  |
| Monitoring post-d√©ploiement   | Evidently, Prometheus    | Vertex AI Monitoring, Azure Monitor |

---

## Pi√®ges fr√©quents et solutions

### üî∏ Probl√®me : R√©sultats non reproductibles

**Cause** : versions de donn√©es ou code non fig√©es, pipelines manuels
**Solution** : DVC pour les donn√©es, MLflow pour l‚Äôexp√©rimentation, scripts versionn√©s

### üî∏ Probl√®me : Environnement local ‚â† production

**Cause** : d√©pendances floues, configurations sp√©cifiques non portables
**Solution** : Dockerisation stricte, gestion centralis√©e des secrets

### üî∏ Probl√®me : D√©rive silencieuse des donn√©es ou du mod√®le

**Cause** : manque de monitoring m√©tier
**Solution** : Evidently + Prometheus avec alertes sur les m√©triques cl√©s

### üî∏ Probl√®me : Frictions entre √©quipes Data / Ops

**Cause** : r√¥les mal d√©finis, manque d'automatisation
**Solution** : pipelines automatis√©s, documentation partag√©e, GitOps appliqu√© au ML



---

# Chapitre 2 ‚Äî Gestion des donn√©es

## Collecte et ingestion de donn√©es

La premi√®re √©tape d‚Äôun pipeline MLOps est l‚Äôacquisition des donn√©es. Celles-ci peuvent provenir de sources vari√©es :

* Bases de donn√©es relationnelles (PostgreSQL, MySQL)
* Fichiers plats (CSV, JSON, Parquet)
* APIs externes (REST, GraphQL)
* Flux temps r√©el (Kafka, MQTT)
* Donn√©es cloud (S3, GCS, Azure Blob)

La collecte peut √™tre automatis√©e via des outils comme **Airflow**, **Prefect**, ou des scripts d√©di√©s int√©gr√©s dans un pipeline DVC ou MLflow.

### Bonnes pratiques :

* Centraliser les acc√®s via une couche d‚Äôabstraction
* Documenter chaque source (structure, fr√©quence, format)
* S√©parer la phase d‚Äôextraction de la phase de transformation

### Exemple d'impl√©mentation avec Airflow (ingestion automatique d'un dataset public)

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.utils.dates import days_ago

dag = DAG(
    'ingest_csv_kaggle',
    default_args={'owner': 'mlops'},
    start_date=days_ago(1),
    schedule_interval='@daily'
)

ingest = BashOperator(
    task_id='download_data',
    bash_command='curl -o /data/raw.csv https://url-vers-dataset.csv',
    dag=dag
)
```

---

## Validation des donn√©es

Avant toute utilisation, les donn√©es doivent √™tre valid√©es pour √©viter les erreurs silencieuses en aval. Les erreurs peuvent inclure :

* Types incoh√©rents
* Donn√©es manquantes ou aberrantes
* Distributions inattendues

### Outils de validation :

* **Great Expectations** : framework d√©claratif de tests de donn√©es
* **Pandera** : validation de DataFrames Pandas avec des sch√©mas typ√©s
* **Deepchecks** : tests orient√©s machine learning (biais, drift, etc.)

### Exemple avanc√© avec Great Expectations

```python
from great_expectations.dataset import PandasDataset
import pandas as pd

class MyValidatedDataset(PandasDataset):
    _expectations_config = {
        "expect_column_values_to_not_be_null": {"column": "age"},
        "expect_column_values_to_be_between": {"column": "age", "min_value": 0, "max_value": 120}
    }

df = pd.read_csv("/data/clean.csv")
validated_df = MyValidatedDataset(df)
validated_df.validate()
```

### Int√©gration dans CI/CD

* Ajouter un job `validate_data` dans GitHub Actions avec un rapport JSON
* Failer le pipeline si un seuil de conformit√© est franchi

---

## Versionnage de donn√©es

Contrairement au code, les donn√©es changent souvent et doivent √™tre versionn√©es pour garantir la reproductibilit√© des exp√©riences ML.

### Outils :

* **DVC** (Data Version Control) : s‚Äôint√®gre √† Git pour tracker les fichiers volumineux
* **LakeFS** : transforme un data lake en syst√®me de fichiers versionn√©
* **Delta Lake** : versionning transactionnel sur Apache Spark

### Exemple : DVC avec Google Cloud

```bash
dvc init
dvc remote add -d gcsremote gcs://bucket/dataset
dvc add data/clean.csv
git add data/clean.csv.dvc .gitignore
git commit -m "Ajout dataset versionn√©"
dvc push
```

### Bonne pratique : cr√©er un tag Git associ√© √† chaque version de dataset

```bash
git tag -a "v_dataset_202406" -m "Version stable du dataset de juin 2024"
git push origin v_dataset_202406
```

---

## Data Warehouses vs Data Lakes

### Data Warehouses (Entrep√¥ts de donn√©es)

* Stockage structur√©, optimis√© pour les requ√™tes SQL
* Donn√©es propres, mod√©lis√©es (ex : BigQuery, Snowflake, Redshift)
* Id√©al pour les rapports, BI, agr√©gations

### Data Lakes

* Stockage brut, souvent en fichiers (ex : S3, GCS, HDFS)
* Supporte donn√©es structur√©es / semi-structur√©es / non structur√©es
* Adapt√© √† la Data Science, traitement batch ou streaming

### √âvolution :

* **Lakehouse** = combinaison des deux (ex : Databricks Delta Lake)

### Choix en contexte industriel :

| Crit√®re              | Warehouse              | Lake               | Lakehouse (hybride)     |
| -------------------- | ---------------------- | ------------------ | ----------------------- |
| Co√ªt                 | √âlev√©                  | Faible √† mod√©r√©    | Mod√©r√©                  |
| Performance requ√™tes | Optimis√©e (indexation) | Moyenne            | Bonne avec Delta Engine |
| Volume & vari√©t√©     | Limit√©                 | Massif, tous types | Massif + structuration  |
| Use case typique     | BI, dashboards         | IA, Big Data, logs | MLOps, BI + ML          |

---

## Donn√©es sensibles : anonymisation, RGPD, etc.

Le traitement de donn√©es personnelles (noms, e-mails, logs, donn√©es m√©dicales, etc.) est soumis √† des r√©gulations strictes comme le **RGPD**.

### Principes fondamentaux :

* Minimisation des donn√©es : ne collecter que ce qui est utile
* Droit √† l‚Äôoubli : suppression √† la demande
* Consentement explicite de l‚Äôutilisateur

### Techniques d‚Äôanonymisation :

* **Masquage** : remplacement des donn√©es sensibles
* **Pseudonymisation** : transformation r√©versible avec cl√©
* **Diff√©rential Privacy** : ajout de bruit contr√¥l√© aux donn√©es/statistiques

### Impl√©mentation : pseudonymisation simple

```python
import hashlib

def pseudonymize_email(email: str) -> str:
    return hashlib.sha256(email.encode()).hexdigest()
```

### Bonnes pratiques MLOps :

* Logger les acc√®s aux donn√©es sensibles
* S√©parer donn√©es sensibles des features utilis√©es
* Documenter les politiques de r√©tention et d'acc√®s
* Int√©grer les v√©rifications RGPD dans les checklists de mise en production

---

# Chapitre 3 ‚Äî Environnements de d√©veloppement

## Environnements reproductibles

### Pourquoi ?

Dans le cycle de vie MLOps, il est crucial de garantir que les r√©sultats obtenus dans un environnement (ex. notebook local) soient reproductibles ailleurs (en CI/CD, sur serveur ou en production).

### Outils majeurs :

* **Conda** : gestion d‚Äôenvironnements et de d√©pendances isol√©s
* **virtualenv / venv** : standard Python plus l√©ger
* **Docker** : conteneurisation compl√®te de l‚Äôenvironnement OS + d√©pendances

### Exemple : Dockerfile pour un environnement ML typique

```Dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --upgrade pip && pip install -r requirements.txt

COPY . .
CMD ["python", "src/train.py"]
```

### Recommandations :

* Figer les versions de chaque d√©pendance (pas de `scikit-learn>=1.0`)
* Documenter la proc√©dure de setup local, cloud, CI/CD
* Versionner l‚Äôenvironnement (ex. `environment.lock.yaml`, `Dockerfile`) au m√™me titre que le code

---

## Gestion des d√©pendances

Une mauvaise gestion des d√©pendances est la cause fr√©quente de bugs non reproductibles ou d‚Äô√©checs en production.

### Outils :

* **pip + requirements.txt** : simple et standard, mais peu strict
* **Poetry** : gestion moderne avec r√©solution et lockfile
* **pipenv** : alternative avec fichiers `Pipfile` et `Pipfile.lock`

### Exemple avanc√© avec Poetry

```bash
poetry init
poetry add pandas scikit-learn mlflow
poetry export -f requirements.txt --output requirements.txt --without-hashes
```

### Bonnes pratiques :

* Utiliser un lockfile (`poetry.lock`, `Pipfile.lock`, etc.) dans tous les environnements
* Automatiser les installations dans vos workflows CI/CD
* Utiliser `pip freeze > requirements.txt` uniquement pour archiver un √©tat fig√©

---

## Jupyter vs IDE vs Notebooks orchestr√©s

### Jupyter (Notebook local)

* Exploratoire, rapide √† utiliser, mais peu reproductible
* Faible tra√ßabilit√© (sauf avec nbconvert, papermill, etc.)

### IDE (VSCode, PyCharm, etc.)

* D√©veloppement structur√©, bon pour projets complexes
* Compatible avec d√©bogage, tests, linting

### Notebooks orchestr√©s

* Utilisent **Papermill**, **Dagster**, **Metaflow**, etc. pour ex√©cuter des notebooks dans des pipelines reproductibles

### Exemple avec Papermill

```bash
papermill input.ipynb output.ipynb -p learning_rate 0.01 -p n_estimators 100
```

### Recommandations :

* Convertir les notebooks en scripts (`nbconvert`) avant CI/CD
* Journaliser tous les param√®tres et outputs (MLflow, Weights & Biases)
* Ne pas mettre en production un `.ipynb` directement

---

## Bonnes pratiques de gestion de code

### Utilisation de Git

* Branches par fonctionnalit√© ou par exp√©rimentation (`exp/`, `feat/`, `hotfix/`)
* Commits atomiques, messages clairs et normalis√©s (ex : Conventional Commits)

### Pre-commit hooks

* V√©rifications automatiques : formatage, typage, tests, lint
* Outils : `pre-commit`, `black`, `flake8`, `mypy`

### Exemple : configuration `.pre-commit-config.yaml`

```yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black

  - repo: https://github.com/pre-commit/mirrors-flake8
    rev: v6.0.0
    hooks:
      - id: flake8
```

### Bonnes pratiques :

* Int√©grer les tests et hooks dans les workflows GitHub Actions
* G√©n√©rer un changelog automatiquement √† partir des commits (conventional changelog)
* Coupler gestion du code, des notebooks, des mod√®les et des artefacts dans une strat√©gie Git unifi√©e


### Int√©grer les tests et hooks dans les workflows GitHub Actions

L‚Äôobjectif est d‚Äô√©viter toute r√©gression ou code non conforme d√®s le push.

#### Exemple de workflow `.github/workflows/checks.yml`

```yaml
name: checks

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install black flake8 mypy pytest

      - name: Lint
        run: |
          black --check .
          flake8 .
          mypy src/

      - name: Run tests
        run: pytest tests/
```

---

### G√©n√©rer un changelog automatiquement √† partir des commits

#### Pourquoi ?

Pour faciliter les releases, communiquer efficacement les changements, et maintenir la documentation √† jour.

#### M√©thodes :

* Convention de nommage de commits : **Conventional Commits**
* Outils :

  * `standard-version` (JS/npm)
  * `cz` / `commitizen` (Python-compatible)
  * `semantic-release` (automatique avec GitHub Actions)

#### Exemple avec `cz`

```bash
pip install commitizen
cz init  # Configure avec pyproject.toml
cz bump  # Incr√©mente version + changelog auto
cz changelog  # G√©n√®re ou met √† jour CHANGELOG.md
```

---

### Strat√©gie unifi√©e : code, notebooks, mod√®les, artefacts

Une bonne approche consiste √† versionner et structurer **l‚Äôensemble du cycle de vie ML** dans un d√©p√¥t coh√©rent et automatis√©.

#### Structure recommand√©e

```
repo/
‚îú‚îÄ‚îÄ notebooks/              # Explorations initiales (tracking MLflow ou Papermill)
‚îú‚îÄ‚îÄ src/                    # Code de production modulaire
‚îú‚îÄ‚îÄ models/                 # Fichiers de mod√®les export√©s (liens DVC ou MLflow)
‚îú‚îÄ‚îÄ data/                   # Symboliques DVC ou r√©pertoire ignor√©
‚îú‚îÄ‚îÄ tests/                  # Tests unitaires, d‚Äôint√©gration, etc.
‚îú‚îÄ‚îÄ mlruns/                 # Logs MLflow (si local)
‚îú‚îÄ‚îÄ .github/workflows/      # Pipelines CI/CD
‚îú‚îÄ‚îÄ Dockerfile              # Environnement conteneuris√©
‚îú‚îÄ‚îÄ dvc.yaml                # Pipelines de traitement data
‚îî‚îÄ‚îÄ pyproject.toml          # Config globale (formatage, version, changelog, etc.)
```

#### Automatisations

* CI/CD d√©clenchant : lint ‚Üí test ‚Üí train ‚Üí log mod√®le ‚Üí push artefact ‚Üí d√©ploiement
* Git tags d√©clenchant des versions + changelogs + publication
* Liaison avec MLflow pour chaque commit/tag

---

### R√®gles de relecture de code en √©quipe ML

* Toute pull request doit contenir :

  * description claire
  * justification m√©tier/technique
  * preuves reproductibles (ex : run ID MLflow)
* Revue obligatoire √† deux pairs pour les √©tapes critiques : ingestion, entra√Ænement, scoring
* Tests automatis√©s requis avant merge, avec rapport dans le commentaire PR


---

# Chapitre 4 ‚Äî Exp√©rimentation et suivi

## Suivi des exp√©riences

L'entra√Ænement de mod√®les implique l'exploration d'une multitude de combinaisons : algorithmes, hyperparam√®tres, jeux de donn√©es, strat√©gies de preprocessing. Documenter et tracer ces exp√©riences est essentiel pour garantir la reproductibilit√© et identifier les meilleurs r√©sultats.

### Outils de tracking

* **MLflow Tracking** : open source, extensible, tr√®s utilis√©
* **Weights & Biases (W\&B)** : complet, orient√© collaboration
* **Neptune.ai** : interface puissante avec gestion d‚Äô√©quipes
* **Comet ML** : supporte m√©triques, graphiques, comparaison d‚Äôexp√©riences

### Exemple : tracking avec MLflow

```python
import mlflow

mlflow.start_run()
mlflow.log_param("learning_rate", 0.01)
mlflow.log_metric("accuracy", 0.91)
mlflow.sklearn.log_model(model, "model")
mlflow.end_run()
```

### Bonnes pratiques

* Utiliser des tags et noms explicites (`exp_baseline_lr001`, `tuned_random_forest`)
* Lier les run IDs √† des commits Git
* Stocker les artefacts de mod√®le dans un registre (MLflow Registry ou DVC)
* Versionner les donn√©es avec DVC et les r√©f√©rencer dans l‚Äôexp√©rience
* Mettre en place un tableau de bord centralis√© (ex. via `mlflow ui` ou `W&B Reports`)

---

## Gestion des hyperparam√®tres

Les hyperparam√®tres influencent fortement la performance d‚Äôun mod√®le. Leur recherche doit √™tre syst√©matis√©e et reproductible.

### M√©thodes classiques

* Grid Search : exploration exhaustive
* Random Search : √©chantillonnage al√©atoire

### M√©thodes avanc√©es

* **Bayesian Optimization** : ex. avec `optuna`
* **Hyperband** : algorithme adaptatif efficace
* **Population-Based Training** : strat√©gies √©volutives (ex. Ray Tune)

### Exemple avec Optuna

```python
import optuna

def objective(trial):
    lr = trial.suggest_float("lr", 1e-4, 1e-1, log=True)
    clf = SomeModel(learning_rate=lr)
    accuracy = cross_val_score(clf, X, y).mean()
    return accuracy

study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=50)
```

### Bonnes pratiques

* D√©finir des espaces de recherche r√©alistes
* Combiner Optuna avec MLflow pour tracker automatiquement les runs
* Limiter le co√ªt par run via early stopping ou r√©duction de dataset
* Parall√©liser les recherches (Ray, Optuna, SageMaker Tuning Jobs)

---

## R√©plication des exp√©riences

### Pourquoi c‚Äôest crucial ?

* Garantir que les r√©sultats sont fiables, pas dus au hasard ou √† des fuites
* Permettre √† d'autres √©quipes ou √† la CI/CD de relancer un entra√Ænement identique

### Strat√©gies

* Fixer les seeds al√©atoires (NumPy, Torch, TensorFlow)
* Versionner **tout** : code, data, config, mod√®le, environnement
* Centraliser la configuration via Hydra ou YAML/JSON

### Exemple : script totalement r√©plicable

```bash
python train.py --config config.yaml --seed 42
```

```yaml
# config.yaml
model:
  type: xgboost
  max_depth: 7
  learning_rate: 0.01

training:
  test_split: 0.2
  n_estimators: 500
```

---

## Comparaison des mod√®les

Une fois plusieurs mod√®les entra√Æn√©s, il est essentiel de comparer leurs performances de mani√®re rigoureuse.

### M√©triques courantes

* **Classification** : accuracy, precision, recall, F1-score, ROC AUC
* **R√©gression** : RMSE, MAE, R¬≤
* **Surv√™tement ?** : courbes d‚Äôapprentissage, courbes de validation crois√©e

### Outils de visualisation

* **MLflow UI** : graphiques et tableaux d‚Äôexp√©riences
* **W\&B Sweeps** : visualisation interactive
* **TensorBoard** : pour les frameworks deep learning

### Bonnes pratiques

* Comparer non seulement la performance, mais aussi :

  * la stabilit√© (√©cart-type sur k-folds)
  * le co√ªt d‚Äôentra√Ænement (temps, m√©moire)
  * la taille du mod√®le (pour le d√©ploiement)
* Documenter toutes les comparaisons dans un changelog exp√©rimental versionn√©
* Garder un mod√®le ¬´ champion ¬ª par t√¢che dans un registre et archiver les anciens

---

# Chapitre 5 ‚Äî Entra√Ænement des mod√®les

## Local, cloud et hybride : strat√©gies d'entra√Ænement

### Entra√Ænement local

* Avantages : rapide √† mettre en ≈ìuvre, pas de co√ªt cloud
* Limites : ressources limit√©es (RAM, GPU), non scalable, reproductibilit√© manuelle

### Entra√Ænement sur le cloud

* Services manag√©s : AWS SageMaker, Google Vertex AI, Azure ML
* Infrastructure IaaS : Kubernetes + GPU (ex. GKE, AKS, EKS)

### Strat√©gie hybride

* Pr√©-traitement et prototypage en local
* Entra√Ænement distribu√© et orchestration sur cloud
* Artefacts synchronis√©s via DVC, MLflow, ou stockage object (S3, GCS)

### Bonnes pratiques

* Automatiser les transferts de donn√©es et mod√®les
* D√©clencher les entra√Ænements depuis un pipeline CI/CD (GitHub Actions, Airflow)
* S√©curiser les acc√®s cloud avec secrets manager ou vault

---

## Acc√©l√©ration avec GPU/TPU

### Frameworks compatibles

* TensorFlow, PyTorch, JAX, RAPIDS (cuDF, cuML)

### Bonnes pratiques :

* Activer le profiling GPU (`torch.cuda.Profiler`, `tf.profiler`)
* Lib√©rer explicitement la m√©moire GPU entre les runs
* Mesurer le **batch size maximal** par mod√®le pour optimiser l'utilisation

### Exemple (PyTorch)

```python
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = MyModel().to(device)
```

### TPUs

* Disponibles via Google Cloud ou Colab
* Id√©al pour mod√®les massifs ou entra√Ænement distribu√© √† grande √©chelle

---

## Orchestration d'entra√Ænement

Un entra√Ænement en production ne se lance jamais manuellement : il est orchestr√©.

### Outils open-source :

* **Airflow** : DAGs, scheduling, d√©pendances
* **Prefect** : workflow Pythonic, r√©silient
* **Kubeflow Pipelines** : pour K8s, avec support ML complet
* **Dagster** : typage fort, monitoring int√©gr√©

### Exemple : DAG Airflow simplifi√©

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def train_model():
    ... # logiques d'entra√Ænement

dag = DAG(
    'train_model_pipeline',
    start_date=datetime(2023, 1, 1),
    schedule_interval='@daily'
)

train_task = PythonOperator(
    task_id='train_model',
    python_callable=train_model,
    dag=dag
)
```

### Bonnes pratiques

* G√©rer les √©checs avec des retries et des alertes
* S√©parer les √©tapes : preprocessing ‚Üí entra√Ænement ‚Üí √©valuation ‚Üí packaging
* Utiliser un DAG versionn√© avec `dvc.yaml` pour les pipelines data

---

## Gestion des ressources

### Sc√©narios fr√©quents

* Mod√®le trop lent ? ‚Üí profiler et parall√©liser (batching, num\_workers)
* Trop gourmand ? ‚Üí simplifier (distillation, pruning, quantization)
* Entra√Ænement interrompu ? ‚Üí checkpoints fr√©quents, reprise automatique

### Optimisations cl√©s

* **DataLoader** bien param√©tr√© (shuffle, num\_workers, pin\_memory)
* **Mixed Precision Training** (ex: `torch.cuda.amp`) : acc√©l√®re sans perte significative
* **Early stopping** : √©viter d'√©puiser inutilement les ressources

### Exemple : mixed precision training (PyTorch)

```python
from torch.cuda.amp import GradScaler, autocast

scaler = GradScaler()
for inputs, targets in dataloader:
    optimizer.zero_grad()
    with autocast():
        outputs = model(inputs)
        loss = criterion(outputs, targets)
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

---

## Distribution de l'entra√Ænement

### Approches :

* **Data Parallel** : m√™me mod√®le sur plusieurs GPU (PyTorch DDP, Horovod)
* **Model Parallel** : mod√®le r√©parti sur plusieurs machines (gros LLM)
* **Parameter Server** : partage centralis√© des poids

### Outils/frameworks

* **PyTorch Lightning + DDP**
* **Ray Train** : orchestration distribu√©e moderne
* **SageMaker Training Jobs** : distribu√© et manag√©
* **Accelerate (Hugging Face)** : wrappe DDP/TPU/CPU facilement

### Exemple : DDP avec PyTorch Lightning

```python
from pytorch_lightning import Trainer

trainer = Trainer(
    accelerator="gpu",
    devices=4,
    strategy="ddp"
)
trainer.fit(model, dataloader)
```

### Bonnes pratiques

* Monitorer les workers distribu√©s (logs + Prometheus/Grafana)
* Synchroniser les artefacts entre n≈ìuds
* Tester d‚Äôabord en local avec 1 worker simul√© (`--num_processes=1`)

---

# Chapitre 6 ‚Äî Tests & Validation des mod√®les

## Tests unitaires pour le code ML

M√™me dans un projet de data science, tout le code doit √™tre test√© :

* Fonctions de preprocessing
* Fonctions d‚Äôing√©nierie de features
* M√©triques personnalis√©es
* Chargement/s√©rialisation de mod√®le

### Outils recommand√©s :

* **pytest** : framework de test Python standard
* **hypothesis** : tests de propri√©t√© (valeurs al√©atoires intelligentes)
* **tox** ou **nox** : tests sur plusieurs environnements

### Exemple : test unitaire d‚Äôune fonction de normalisation

```python
def normalize(x):
    return (x - x.mean()) / x.std()

def test_normalize():
    import numpy as np
    x = np.array([1, 2, 3, 4, 5])
    z = normalize(x)
    assert np.isclose(z.mean(), 0.0, atol=1e-6)
    assert np.isclose(z.std(), 1.0, atol=1e-6)
```

---

## Tests de performance et robustesse

Les mod√®les doivent √™tre √©valu√©s au-del√† des seules m√©triques standard.

### Types de tests :

* **Stress tests** : √©valuer la stabilit√© avec des inputs bruit√©s ou extr√™mes
* **Tests de performance** : latence, RAM/VRAM, d√©bit (inference/sec)
* **Tests m√©tier** : sensibilit√© √† des cas cl√©s ou critiques

### Exemple : test de robustesse √† des valeurs aberrantes

```python
def test_model_robustness():
    X_outlier = generate_abnormal_inputs()
    predictions = model.predict(X_outlier)
    assert not np.any(np.isnan(predictions))
```

### Bonnes pratiques :

* Suivre une **courbe pr√©cision/latence** pour arbitrage
* Int√©grer ces tests dans les workflows de validation
* Exiger une robustesse document√©e avant mise en production

---

## D√©tection de d√©rive (drift) et biais

Les mod√®les peuvent perdre en pertinence si la distribution des donn√©es change (d√©rive) ou s‚Äôils amplifient des in√©galit√©s (biais).

### Types de d√©rives :

* **Data drift** : changement dans les features d‚Äôentr√©e
* **Concept drift** : changement dans la relation X ‚Üí Y

### Outils de d√©tection :

* **Evidently** (open-source, simple √† int√©grer)
* **Fiddler**, **WhyLabs**, **Amazon Clarify** (solutions SaaS)
* **Scikit-multiflow** pour les flux en ligne

### Exemple avec Evidently

```python
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset

report = Report(metrics=[DataDriftPreset()])
report.run(reference_data=df_ref, current_data=df_prod)
report.save_html("drift_report.html")
```

### Tests anti-biais :

* Probl√®mes : d√©s√©quilibre, traitement in√©quitable, proxies indirects
* M√©triques : Equal Opportunity, Demographic Parity, TPR/FPR gap
* R√©parations : re-weighting, post-processing, fairness-aware learning

---

## Validation crois√©e automatique

La validation crois√©e (cross-validation) √©value la g√©n√©ralisation du mod√®le. Elle doit √™tre syst√©matis√©e dans les pipelines.

### M√©thodes principales :

* K-Fold (stratifi√© ou non)
* Leave-One-Out
* Time Series Split (pour donn√©es temporelles)

### Impl√©mentation avec `sklearn`

```python
from sklearn.model_selection import cross_validate

scores = cross_validate(model, X, y,
                        scoring=["accuracy", "f1"],
                        cv=5,
                        return_train_score=True)
print(scores)
```

### Bonnes pratiques :

* Toujours stratifier les splits en classification
* S√©parer pipeline d‚Äôentra√Ænement et validation (eviter les fuites de donn√©es)
* Logguer tous les splits, seeds, et scores dans MLflow
* √âtendre la validation crois√©e aux pipelines complets (avec `Pipeline` sklearn, `Optuna`, `PyCaret`, etc.)


---

# Chapitre 7 ‚Äî D√©ploiement des mod√®les

## Mod√®les servables : formats et compatibilit√©

Avant tout d√©ploiement, un mod√®le doit √™tre **export√© dans un format standardis√©**.

### Formats de s√©rialisation

* **Pickle / Joblib** : sp√©cifique √† Python, non s√©curis√© (ne jamais charger depuis une source non fiable)
* **ONNX (Open Neural Network Exchange)** : format inter-framework, compatible avec C++, JavaScript, mobile, edge
* **TorchScript** : optimis√© pour la production avec PyTorch
* **TensorFlow SavedModel** : standard de TensorFlow

### Bonnes pratiques

* Exporter avec version, signature d‚Äôentr√©e/sortie, m√©tadonn√©es
* Valider les entr√©es avec des sch√©mas (pydantic, marshmallow, OpenAPI)
* Tester les mod√®les apr√®s export avec des tests fonctionnels

---

## D√©ploiement avec Flask/FastAPI

### Usage : exposer le mod√®le en tant qu‚ÄôAPI REST

### Exemple avec FastAPI

```python
from fastapi import FastAPI
from pydantic import BaseModel
import joblib

app = FastAPI()
model = joblib.load("model.joblib")

class Input(BaseModel):
    feature1: float
    feature2: float

@app.post("/predict")
def predict(input: Input):
    data = [[input.feature1, input.feature2]]
    prediction = model.predict(data)
    return {"prediction": prediction.tolist()}
```

### Bonnes pratiques

* Ajouter Swagger (auto-g√©n√©r√©)
* Ajouter validation stricte des entr√©es
* Journaliser les requ√™tes et latence (via middleware)
* S√©parer service API / logique m√©tier / mod√®le pour maintenabilit√©

---

## Docker + Kubernetes : production scalable

### Dockerisation

* Fournit un environnement isol√© et reproductible
* Facilite la portabilit√© : local ‚Üí CI ‚Üí cloud

### Exemple : Dockerfile

```dockerfile
FROM python:3.10
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]
```

### Kubernetes

* Orchestration de containers : scaling, rolling updates, auto-recovery
* YAML de d√©ploiement typique :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ml-api
  template:
    metadata:
      labels:
        app: ml-api
    spec:
      containers:
      - name: api
        image: myorg/ml-api:latest
        ports:
        - containerPort: 8080
```

### Bonnes pratiques

* Utiliser des **probes** (liveness/readiness)
* Centraliser les logs avec Fluentd ou Loki
* G√©rer les secrets avec K8s secrets ou Hashicorp Vault
* Surveiller avec Prometheus + Grafana

---

## Serveurs de mod√®les sp√©cialis√©s

### Solutions

* **MLflow Models** : serveurs REST auto-g√©n√©r√©s (mlflow models serve)
* **TensorFlow Serving** : performant pour mod√®les TF
* **TorchServe** : optimis√© pour mod√®les PyTorch
* **MLServer** : standard compatible avec BentoML, FastAPI, SKLearn

### Avantages

* Meilleures performances qu‚Äôun serveur API maison
* Int√©gration native avec des pipelines CI/CD
* Multiples mod√®les, versioning, autoscaling natif (ex : Seldon Core)

### Exemple : servir un mod√®le avec MLflow

```bash
mlflow models serve -m runs:/<run-id>/model --port 1234
```

---

## Services manag√©s (SageMaker, Vertex AI, Azure ML)

### Quand les utiliser ?

* √âquipes petites ou non expertes en infra
* Besoin de gestion simplifi√©e du cycle complet (train + deploy + monitor)

### Fonctionnalit√©s typiques

* One-click deployment
* Auto-scaling & A/B testing
* Monitoring int√©gr√©
* Mod√®le registry et gestion des versions

### Inconv√©nients

* Co√ªt √©lev√© √† l‚Äô√©chelle
* Verrouillage propri√©taire (vendor lock-in)
* Personnalisation limit√©e

---

## CI/CD pour mod√®les ML

### Objectifs

* Automatiser : tests ‚Üí packaging ‚Üí validation ‚Üí d√©ploiement
* Versionner tous les artefacts (mod√®le, data, code, config)

### Pipelines typiques

1. Trigger : push/tag Git ou validation humaine
2. Test du mod√®le (fonctionnel + perf)
3. Packaging (Docker, ONNX, archive MLflow)
4. Publication (registry, S3, DVC remote)
5. D√©ploiement (API, Kubernetes, cloud)

### Exemple de pipeline GitHub Actions (d√©ploiement MLflow)

```yaml
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install deps & MLflow
        run: pip install -r requirements.txt mlflow

      - name: Deploy model
        run: mlflow models serve -m runs:/latest/model --port 5000
```

### Bonnes pratiques

* S√©parer les jobs train/test/deploy
* Restreindre les d√©ploiements au main ou √† certains tags (`v*.*.*`)
* Ajouter un environnement de staging
* Monitorer les latences post-d√©ploiement automatiquement

---

# Chapitre 8 ‚Äî Surveillance en production

## Monitoring des performances de mod√®les

Une fois d√©ploy√©, un mod√®le doit √™tre surveill√© en continu pour garantir :

* Sa disponibilit√© (temps de r√©ponse, uptime)
* Sa performance m√©tier (pr√©cision, recall, etc.)
* L'absence de d√©rive statistique (features, labels)
* L‚Äôusage effectif de ses pr√©dictions

### Outils utilis√©s

* **Prometheus** : collecte de m√©triques
* **Grafana** : visualisation
* **Evidently** : d√©tection automatique de d√©rive
* **Seldon Core / Alibi Detect** : framework pour ML sur Kubernetes avec outils de monitoring int√©gr√©s

### Exemple : m√©triques Prometheus expos√©es depuis FastAPI

```python
from prometheus_client import Counter, Histogram, start_http_server

prediction_count = Counter('predictions_total', 'Total predictions made')
prediction_latency = Histogram('prediction_latency_seconds', 'Time for prediction')

@app.post("/predict")
@prediction_latency.time()
def predict(input: Input):
    prediction_count.inc()
    return {"prediction": model.predict(...)}
```

---

## Logging et tra√ßabilit√©

Chaque appel au mod√®le doit √™tre logg√© :

* Entr√©es utilisateur (apr√®s validation/anonymisation)
* Timestamp, user ID ou session ID
* Temps de r√©ponse, statut
* R√©sultat retourn√© (et √©ventuelle probabilit√© ou confiance)

### Bonnes pratiques

* Ajouter un middleware de journalisation
* Utiliser des outils comme **ELK Stack** (Elasticsearch + Logstash + Kibana), **Loki**, ou **Fluentd**
* Corr√©ler logs applicatifs avec les m√©triques de mod√®le
* S'assurer de la conformit√© RGPD pour les logs de production

### Exemple : middleware FastAPI

```python
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start = time.time()
    response = await call_next(request)
    duration = time.time() - start
    log.info(f"{request.method} {request.url} {duration:.3f}s")
    return response
```

---

## Alerte sur les m√©triques cl√©s

Un mod√®le peut √™tre silencieusement d√©grad√© en production.

### Cas fr√©quents √† d√©tecter

* Augmentation brutale du taux d'erreur ou des requ√™tes nulles
* Chute soudaine de pr√©cision ou de score m√©tier
* Changements dans la distribution des entr√©es (drift)

### Syst√®me d‚Äôalerte

* **Alertmanager** (coupl√© √† Prometheus)
* Notifications : Slack, e-mail, webhook, dashboard visuel

### Exemple : r√®gle d‚Äôalerte Prometheus

```yaml
groups:
- name: model_alerts
  rules:
  - alert: HighLatency
    expr: prediction_latency_seconds_bucket{le="1.0"} < 0.5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Latence de pr√©diction √©lev√©e"
```

---

## Mise √† jour continue des mod√®les

M√™me les meilleurs mod√®les doivent √™tre mis √† jour p√©riodiquement. En production, cela peut √™tre fait de mani√®re :

* Manuelle (re-training p√©riodique avec validation humaine)
* Automatis√©e (re-training d√©clench√© par d√©tection de d√©rive ou baisse de performance)

### Techniques et outils

* **Scheduled retraining** via Airflow ou Prefect
* **Continuous Training (CT)** avec d√©tection automatique + d√©clenchement pipeline
* **Shadow deployment** : tester le nouveau mod√®le sans l‚Äôexposer (split du trafic)
* **Canary release** : d√©ploiement progressif pour valider la nouvelle version

### √âtapes d‚Äôun cycle complet

1. Surveillance et collecte continue (logs, m√©triques, d√©rive)
2. D√©clenchement conditionnel ou p√©riodique
3. R√©entra√Ænement (sur les nouvelles donn√©es collect√©es)
4. Validation
5. Publication ou rollback selon r√©sultats

### Exemple de d√©clenchement Airflow

```python
def check_drift():
    drift = run_drift_detector()
    return "retrain" if drift else "skip"

branch = BranchPythonOperator(
    task_id='drift_check',
    python_callable=check_drift,
    dag=dag
)
```

---

## Synth√®se

Surveiller un mod√®le en production ne se limite pas √† v√©rifier sa disponibilit√©. Il faut √©galement :

* Comprendre l‚Äôusage r√©el du mod√®le
* Maintenir une visibilit√© compl√®te sur les entr√©es, sorties, erreurs
* √ätre en mesure de r√©agir rapidement √† toute d√©rive
* Organiser les mises √† jour sans perturber l‚Äôutilisateur final

Le monitoring d‚Äôun mod√®le doit √™tre trait√© comme un **produit vivant**, √©volutif, avec des responsabilit√©s partag√©es entre data scientists, ing√©nieurs, et op√©rationnels.


---

# Chapitre 9 ‚Äî Automatisation et orchestration

## Pipelines automatis√©s avec Airflow / Prefect

L'automatisation des workflows est cruciale pour garantir la reproductibilit√©, la fiabilit√© et la scalabilit√© des projets ML. Deux outils sont aujourd'hui largement utilis√©s : **Apache Airflow** et **Prefect**.

### Airflow

* Bas√© sur le concept de DAG (Directed Acyclic Graph).
* Chaque t√¢che est un op√©rateur Python ou Bash.
* Excellente extensibilit√© avec des plugins.

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def preprocess():
    # Code de preprocessing
    pass

def train_model():
    # Code d'entra√Ænement
    pass

dag = DAG('ml_pipeline', start_date=datetime(2024, 1, 1), schedule_interval='@daily')

preprocess_task = PythonOperator(task_id='preprocess', python_callable=preprocess, dag=dag)
train_task = PythonOperator(task_id='train', python_callable=train_model, dag=dag)

preprocess_task >> train_task
```

### Prefect

* Plus moderne, plus orient√© objet.
* S'int√®gre facilement √† DVC, MLflow, et des services cloud.

```python
from prefect import flow, task

@task
def preprocess():
    pass

@task
def train():
    pass

@flow
def ml_flow():
    data = preprocess()
    train()

ml_flow()
```

---

## GitOps appliqu√© au MLOps

GitOps consiste √† piloter l‚Äôensemble des d√©ploiements via Git comme source unique de v√©rit√©. Il est de plus en plus appliqu√© aux projets ML.

### Principes

* D√©ploiement d√©clench√© par des commits Git (push/PR/tag).
* Repos s√©par√©s pour le code, les mod√®les, les donn√©es et la configuration.
* Int√©gration continue + livraison continue (CI/CD) via outils comme ArgoCD, FluxCD.

### Avantages

* Tra√ßabilit√© compl√®te des changements
* Rollback simplifi√©s
* Approche d√©clarative et auditable

### Exemple : d√©ploiement via ArgoCD

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ml-deploy
spec:
  source:
    repoURL: https://github.com/myorg/ml-deploy
    targetRevision: HEAD
    path: k8s/
  destination:
    server: https://kubernetes.default.svc
    namespace: production
  project: default
```

---

## Feature Stores (Feast, Tecton)

Les Feature Stores sont des syst√®mes sp√©cialis√©s pour le stockage, la gestion et la r√©utilisation des variables explicatives.

### Objectifs

* √âviter les d√©rives entre entra√Ænement et production
* Partager les features entre √©quipes et projets
* Suivre le versioning et les mises √† jour

### Feast

* Open-source, tr√®s utilis√©
* Connecteurs vers Redis, BigQuery, Snowflake‚Ä¶

```python
from feast import FeatureStore
store = FeatureStore(repo_path="my_feature_repo")
data = store.get_online_features(
    features=["user_profile:age", "user_profile:gender"],
    entity_rows=[{"user_id": 1234}]
).to_dict()
```

### Tecton

* Solution commerciale tr√®s compl√®te
* Forte int√©gration avec Spark, Kafka, Snowflake‚Ä¶

---

## Entra√Ænement et d√©ploiement en continu (CT/CI/CD/CM)

Le ML a besoin de pipelines robustes qui int√®grent :

* **CT (Continuous Training)** : r√©entra√Ænement automatique √† intervalle ou sur d√©clencheur
* **CI/CD (Int√©gration et livraison continues)** : v√©rification + packaging + d√©ploiement
* **CM (Continuous Monitoring)** : supervision active du mod√®le

### Encha√Ænement typique

1. Nouveau lot de donn√©es ‚Üí d√©clenche le pipeline Airflow
2. R√©entra√Ænement + √©valuation avec MLflow
3. Validation automatis√©e des performances
4. D√©ploiement (si performances > seuil) via GitOps
5. Monitoring d√©clench√© (Prometheus, Grafana, Evidently‚Ä¶)

### Exemple de pipeline CI/CD GitHub Actions

```yaml
name: ml-cicd
on:
  push:
    branches:
      - main
jobs:
  train-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      - name: Install deps
        run: pip install -r requirements.txt
      - name: Train model
        run: python scripts/train.py
      - name: Deploy model
        run: bash deploy.sh
```

L‚Äôautomatisation et l‚Äôorchestration des workflows ML r√©duisent les erreurs humaines, am√©liorent la reproductibilit√©, et acc√©l√®rent le time-to-market des mod√®les. Ce chapitre fournit les briques pour construire des pipelines robustes et scalables, du prototypage au d√©ploiement.

---

---

# Chapitre 10 ‚Äî S√©curit√©, √©thique et conformit√©

## S√©curisation des mod√®les et des APIs

La s√©curit√© des mod√®les de ML ne se limite pas √† l‚Äôacc√®s au mod√®le lui-m√™me. Il faut aussi prot√©ger l‚Äôensemble du pipeline : code, donn√©es, artefacts, endpoints et infrastructure.

### Menaces courantes

* **Reverse engineering de mod√®les** : extraction du mod√®le via des appels API.
* **Attaques par injection de donn√©es** (data poisoning).
* **Attaques par √©vasion** (adversarial examples).
* **Fuites de donn√©es sensibles √† travers les r√©ponses du mod√®le.**

### Bonnes pratiques

* Chiffrement des mod√®les en transit et au repos.
* Authentification forte pour les APIs (OAuth2, JWT).
* Limitation du d√©bit et analyse comportementale des appels API.
* Signature et v√©rification des mod√®les.
* Sandboxing ou conteneurisation de l‚Äôenvironnement d‚Äôinf√©rence.

### Outils et techniques

* **ONNX Runtime avec chiffrement int√©gr√©.**
* **TF Encrypted / PySyft** pour les mod√®les sensibles.
* **API Gateway + WAF (Web Application Firewall)** devant chaque service de ML.

---

## D√©rives algorithmiques, fairness & explainability

### D√©rives algorithmiques

* D√©pendance aux donn√©es de production : d√©rives de distribution.
* Concept drift (changement du sens des variables).
* Bias drift (changement dans l'√©quilibre des classes ou des groupes).

### Fairness (√©quit√©)

* Repr√©sentation biais√©e : minorit√©s mal repr√©sent√©es ‚Üí pr√©dictions injustes.
* M√©triques : Demographic Parity, Equalized Odds, Disparate Impact.
* Strat√©gies : rebalancer les donn√©es, entra√Æner des mod√®les contraints ou appliquer un post-traitement.

### Explainability

* Critique dans les syst√®mes sensibles (sant√©, finance, justice).
* M√©thodes :

  * **SHAP** : importance des features par instance.
  * **LIME** : approximation locale du mod√®le.
  * **Integrated Gradients**, **Captum** pour les r√©seaux de neurones.
* Int√©gration de l‚Äôexplicabilit√© dans les dashboards ou les syst√®mes de d√©cision (sous forme d‚Äôannotations ou d‚Äôanalyses).

---

## Auditabilit√© des mod√®les

L‚Äôauditabilit√© vise √† assurer une tra√ßabilit√© compl√®te des actions, transformations et d√©cisions du pipeline ML.

### Composants cl√©s

* **Suivi des versions de code, de donn√©es, de mod√®les et de param√®tres.**
* **Journaux d'ex√©cution et m√©tadonn√©es d'entra√Ænement.**
* **Enregistrement des inputs/outputs** lors de la pr√©diction.

### Outils

* **MLflow Tracking** avec artefacts versionn√©s.
* **DVC + Git** pour le versioning de datasets et mod√®les.
* **Neptune.ai / Weights & Biases** pour l'observabilit√© √©tendue.

### Objectifs

* R√©trospective sur les performances pass√©es.
* Reproductibilit√© scientifique ou r√©glementaire.
* Contr√¥le qualit√© et analyse des incidents.

---

## Conformit√© r√©glementaire (RGPD, HIPAA)

### RGPD (Europe)

* Minimisation des donn√©es personnelles.
* Droit √† l‚Äôexplication (Art. 22).
* Consentement explicite et r√©vocable.
* Anonymisation ou pseudonymisation obligatoire.
* Encadrement des transferts hors UE.

### HIPAA (√âtats-Unis)

* Protection des donn√©es de sant√© (PHI).
* Audit logs obligatoires.
* Cryptage des transmissions et du stockage.

### Implications concr√®tes

* Choix d‚Äôun h√©bergement conforme.
* Journalisation des acc√®s et des d√©cisions.
* Fourniture d‚Äôun m√©canisme de retrait ou de correction des donn√©es.
* Design du mod√®le orient√© vers la transparence (mod√®les interpr√©tables par design quand c‚Äôest possible).

---

La s√©curit√©, l'√©thique et la conformit√© sont des piliers trop souvent n√©glig√©s dans le d√©ploiement de mod√®les ML. Ce chapitre vous permet de comprendre les risques r√©els, de structurer les r√©ponses techniques et organisationnelles, et de rendre vos syst√®mes auditables, √©quitables et l√©gitimes face √† la soci√©t√© et au droit.


---

---

# Chapitre 11 ‚Äî Cas pratiques

## MLOps complet sur un cas r√©el : pr√©diction de churn

Ce cas pratique met en ≈ìuvre toutes les briques vues pr√©c√©demment, √† travers un projet complet de bout en bout. Nous allons pr√©dire le risque de d√©sabonnement d‚Äôun utilisateur dans un service en ligne, en temps quasi-r√©el.

### Objectif

Anticiper les utilisateurs susceptibles de se d√©sabonner dans les 30 prochains jours afin d'agir proactivement (offre personnalis√©e, relance, etc.).

---

### √âtape 1 : Ingestion de donn√©es

**Source** : √©v√©nements d‚Äôusage collect√©s en continu (clics, connexions, achats, navigation).

**Technologies utilis√©es** :

* **Kafka** : ingestion temps r√©el.
* **Kafka Connect + S3 Sink** : enregistrement dans un lac de donn√©es brut (S3).

**Instructions d√©taill√©es** :

1. Cr√©e un cluster Kafka local avec Docker Compose¬†:

```yaml
version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```

2. Lance avec : `docker-compose up -d`
3. Configure Kafka Connect avec un connecteur S3 Sink (exemple en JSON √† envoyer √† l‚ÄôAPI REST de Kafka Connect)¬†:

```json
{
  "name": "s3-sink",
  "config": {
    "connector.class": "io.confluent.connect.s3.S3SinkConnector",
    "topics": "user-events",
    "s3.bucket.name": "mlops-churn",
    "s3.part.size": 5242880,
    "flush.size": 3,
    "storage.class": "io.confluent.connect.s3.storage.S3Storage",
    "format.class": "io.confluent.connect.s3.format.json.JsonFormat",
    "schema.compatibility": "NONE"
  }
}
```

4. Tester la cha√Æne compl√®te en publiant des messages dans `user-events` et v√©rifier dans S3.

---

### √âtape 2 : Nettoyage & pr√©traitement

**Objectif** : transformer les donn√©es brutes en un format exploitable pour l‚Äôentra√Ænement.

**Technologies utilis√©es** :

* **Apache Spark** pour le traitement distribu√©.
* **DVC (Data Version Control)** pour versionner les jeux de donn√©es nettoy√©s.

**Instructions d√©taill√©es** :

1. Installe Spark localement ou via Docker¬†:

```bash
pip install pyspark
```

2. √âcris un script de transformation PySpark¬†:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_date

spark = SparkSession.builder.appName("Preprocessing").getOrCreate()
df = spark.read.json("s3a://mlops-churn/raw-events/")

cleaned_df = df.filter(col("event_type").isNotNull()) \
              .withColumn("event_date", to_date(col("timestamp"))) \
              .dropna(subset=["user_id"])

cleaned_df.write.parquet("cleaned-data/")
```

3. Versionne les donn√©es avec DVC¬†:

```bash
dvc init
dvc add cleaned-data/
git add cleaned-data.dvc .gitignore
git commit -m "Ajout donn√©es nettoy√©es"
```

4. Connecte DVC √† un stockage distant (ex.¬†: S3, SSH, GDrive).

---

### √âtape 3 : Feature Engineering automatis√©

**Objectif** : extraire des variables pertinentes, historis√©es, et coh√©rentes pour l‚Äôentra√Ænement et l‚Äôinf√©rence.

**Technologies utilis√©es** :

* **Apache Airflow** pour orchestrer le calcul des features.
* **Feast** comme Feature Store.

**Instructions d√©taill√©es** :

1. Installe Feast et configure le projet¬†:

```bash
pip install feast
feast init churn_project
cd churn_project
```

2. Exemple d'entit√© et de features :

```python
# churn_project/feature_repo/entity.py
from feast import Entity
user = Entity(name="user_id", join_keys=["user_id"])

# churn_project/feature_repo/feature_view.py
from feast import FeatureView, Field
from feast.types import Float32
from datetime import timedelta

user_activity_view = FeatureView(
    name="user_activity",
    entities=["user_id"],
    ttl=timedelta(days=30),
    schema=[
        Field(name="avg_session_duration", dtype=Float32),
        Field(name="support_tickets_last_30d", dtype=Float32),
    ],
    online=True,
    source=... # Source d√©finie dans data_source.py
)
```

3. Mat√©rialise les features¬†:

```bash
feast apply
feast materialize-incremental $(date +%F)
```

4. Utilise Airflow pour automatiser les jobs de calcul et de push vers Feast.

---

### √âtape 4 : Entra√Ænement et validation

**Objectif** : entra√Æner un mod√®le robuste sur les donn√©es et valider ses performances avant packaging.

**Technologies utilis√©es** :

* **scikit-learn** ou **XGBoost** pour les mod√®les tabulaires.
* **MLflow** pour le suivi des exp√©riences.
* **DVC** pour versionner les datasets et mod√®les.

**Instructions d√©taill√©es** :

1. Cr√©e un environnement Python d√©di√© :

```bash
python -m venv env
source env/bin/activate
pip install pandas scikit-learn xgboost mlflow dvc
```

2. Pr√©pare les donn√©es (depuis les features mat√©rialis√©es) :

```python
import pandas as pd
from sklearn.model_selection import train_test_split

features = pd.read_parquet("cleaned-data/features.parquet")
X = features.drop("churned", axis=1)
y = features["churned"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```

3. Entra√Æne un mod√®le XGBoost avec suivi MLflow¬†:

```python
import mlflow
import xgboost as xgb
from sklearn.metrics import roc_auc_score

mlflow.start_run()
model = xgb.XGBClassifier(eval_metric="auc")
model.fit(X_train, y_train)

preds = model.predict_proba(X_test)[:, 1]
auc = roc_auc_score(y_test, preds)
mlflow.log_metric("roc_auc", auc)
mlflow.sklearn.log_model(model, "model")
mlflow.end_run()
```

4. Versionne le mod√®le avec DVC :

```bash
dvc add model.pkl
git add model.pkl.dvc
git commit -m "Ajout mod√®le XGBoost"
```

---

### √âtape 5 : Packaging, d√©ploiement et CI/CD

**Objectif** : transformer le mod√®le valid√© en une API d√©ployable, int√©grer dans une cha√Æne CI/CD, et orchestrer les mises √† jour.

**Technologies utilis√©es** :

* **FastAPI** pour exposer l‚ÄôAPI.
* **Docker** pour packager l‚Äôapplication.
* **GitHub Actions** ou **GitLab CI** pour automatiser les tests, le build et le d√©ploiement.
* **Kubernetes** (avec Helm) pour le d√©ploiement.

**Instructions d√©taill√©es** :

#### 1. Cr√©er une API avec FastAPI

```python
# api/app.py
from fastapi import FastAPI, Request
import joblib
import pandas as pd

app = FastAPI()
model = joblib.load("model.pkl")

@app.post("/predict")
async def predict(request: Request):
    data = await request.json()
    df = pd.DataFrame([data])
    prediction = model.predict_proba(df)[0][1]
    return {"churn_probability": prediction}
```

#### 2. Dockeriser l'application

```dockerfile
# Dockerfile
FROM python:3.10
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

**requirements.txt** :

```
fastapi
uvicorn
pandas
scikit-learn
xgboost
joblib
```

#### 3. Construire et tester l‚Äôimage

```bash
docker build -t churn-api .
docker run -p 8000:8000 churn-api
```

Test avec `curl` :

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"feature1": 0.12, "feature2": 3, ...}'
```

#### 4. CI/CD avec GitHub Actions (exemple de `.github/workflows/deploy.yml`)

```yaml
name: Deploy to Kubernetes

on:
  push:
    branches: [main]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Build Docker image
      run: docker build -t ghcr.io/your_user/churn-api:latest .
    - name: Push to GitHub Container Registry
      run: |
        echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u your_user --password-stdin
        docker push ghcr.io/your_user/churn-api:latest
```

#### 5. D√©ploiement Kubernetes avec Helm

```bash
helm create churn-api
```

Dans `values.yaml` :

```yaml
image:
  repository: ghcr.io/your_user/churn-api
  tag: latest
```

Puis :

```bash
helm install churn-api ./churn-api
```

---

### √âtape 6 : Monitoring, drift, alerting

**Objectif** : surveiller les performances du mod√®le en production, d√©tecter les d√©rives, et g√©n√©rer des alertes.

**Technologies utilis√©es** :

* **Prometheus + Grafana** pour les m√©triques.
* **Evidently** pour le suivi de la d√©rive de donn√©es.
* **Sentry** ou **ELK Stack** pour les logs et erreurs.

**Instructions d√©taill√©es** :

1. Int√©grer des m√©triques Prometheus dans FastAPI

```python
from prometheus_client import start_http_server, Summary
start_http_server(8001)  # endpoint Prometheus
REQUEST_TIME = Summary("request_processing_seconds", "Time spent processing request")

@app.post("/predict")
@REQUEST_TIME.time()
async def predict(request: Request):
    ...
```

2. Lancer Prometheus avec configuration :

```yaml
scrape_configs:
  - job_name: 'churn-api'
    static_configs:
      - targets: ['localhost:8001']
```

3. Utiliser Evidently pour le suivi des d√©rives :

```python
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset

report = Report(metrics=[DataDriftPreset()])
report.run(reference_data=ref_df, current_data=prod_df)
report.save_html("drift_report.html")
```

Automatiser cette √©tape chaque semaine avec un DAG Airflow.

4. Alertes avec Grafana (alerting rule sur d√©rive de features cl√©s) ou Sentry pour erreurs API critiques.

---

### √âtape 7 : Bonnes pratiques et erreurs fr√©quentes

* Toujours versionner les datasets ET les mod√®les.
* Ne pas confondre AUC √©lev√©e avec bonne performance r√©elle : attention aux biais.
* Ne pas hardcoder des logiques m√©tier dans l‚ÄôAPI de pr√©diction.
* Mettre √† jour les features et r√©entra√Æner r√©guli√®rement.
* Ne jamais exposer directement des donn√©es sensibles dans les logs.



---

---

# Chapitre 12 ‚Äî Aller plus loin

Ce chapitre explore des sujets avanc√©s du MLOps permettant d‚Äôaller au-del√† du d√©ploiement initial et d‚Äôindustrialiser l‚Äôapproche pour des syst√®mes ML robustes, scalables et dynamiques. On aborde ici des m√©canismes d‚Äôapprentissage actif, de tests A/B, d‚Äôarchitecture multi-tenants et une analyse comparative des solutions open-source et cloud.

---

## 1. Monitoring avec retraining automatique (Active Learning)

### Objectif

Mettre en place un syst√®me capable de d√©tecter les d√©rives et d√©clencher automatiquement le r√©entra√Ænement du mod√®le avec les nouvelles donn√©es jug√©es informatives.

### √âtapes d√©taill√©es

* **Suivi des performances du mod√®le en production** :

  * Collecte des pr√©dictions et v√©rit√©s terrain (quand disponibles).
  * Calcul de m√©triques temporelles (rolling accuracy, f1-score).

* **D√©tection de d√©rive** :

  * Utilisation d‚ÄôEvidently, Alibi Detect ou River pour monitorer le data drift et concept drift.
  * Seuils critiques d√©finis pour d√©clencher une alerte.

* **S√©lection active des exemples** :

  * √âchantillons √† faible confiance du mod√®le (ex : marge faible dans SVM, entropie de softmax √©lev√©e).
  * Choix de la strat√©gie : incertitude, diversit√©, densit√©, hybridation.

* **R√©entra√Ænement automatique** :

  * Orchestration via Airflow / Prefect.
  * Stockage des exemples labellis√©s via feedback utilisateur ou annotation humaine.
  * Mod√®le entra√Æn√©, valid√©, versionn√© puis promu automatiquement si meilleur.

---

## 2. A/B testing sur mod√®les ML

### Objectif

Comparer deux versions d‚Äôun mod√®le en conditions r√©elles, en mesurant leur impact sur des m√©triques m√©tiers et techniques.

### Impl√©mentation

* **Strat√©gies de d√©ploiement** :

  * **Canary release** : petit pourcentage de trafic vers la nouvelle version.
  * **Shadow deployment** : double pr√©diction silencieuse, sans retour utilisateur.

* **Suivi des performances compar√©es** :

  * Collecte des m√©triques m√©tier (taux de conversion, satisfaction).
  * Suivi des erreurs, latence, robustesse.
  * Analyse statistique : test de Student, bootstrap, Bayes factor.

* **Infrastructure** :

  * Istio pour le routage du trafic.
  * MLflow pour le suivi des versions.

---

## 3. Multi-tenancy et scaling MLOps en entreprise

### Objectif

Concevoir une architecture capable de servir plusieurs √©quipes ou clients avec une infrastructure partag√©e, tout en garantissant l‚Äôisolation, la s√©curit√© et la scalabilit√©.

### Approches

* **S√©paration logique ou physique** :

  * Par namespace Kubernetes, projet GCP, ou cluster distinct.

* **Gestion des identit√©s et droits** :

  * RBAC, OAuth, scopes personnalis√©s sur les APIs.

* **D√©ploiement de mod√®les multi-instances** :

  * Serveur de mod√®les (Seldon, KFServing, TorchServe) avec dynamique d‚Äôallocation.

* **Suivi individualis√©** :

  * Dashboards par client ou √©quipe.
  * Logs et m√©triques isol√©s.

---

## 4. Comparaison de stacks MLOps (open-source vs cloud providers)

### Objectif

Aider au choix technologique en comparant les stacks open-source aux solutions cloud manag√©es, selon les besoins du projet.

### Crit√®res compar√©s

| Crit√®re                | Open-source (ex : MLflow + DVC + Airflow) | Cloud (ex : Vertex AI, SageMaker, Azure ML) |
| ---------------------- | ----------------------------------------- | ------------------------------------------- |
| Co√ªt                   | Faible √† mod√©r√©, d√©pend de l‚Äôinfra        | √âlev√©, co√ªt √† l‚Äôusage                       |
| Courbe d‚Äôapprentissage | Plus raide, n√©cessite DevOps              | Interface guid√©e, abstractions √©lev√©es      |
| Flexibilit√©            | Totale, personnalisable                   | Restreinte, d√©pend du provider              |
| Maintenance            | √Ä charge de l‚Äô√©quipe                      | G√©r√©e par le cloud                          |
| Int√©gration CI/CD      | √Ä construire soi-m√™me                     | Int√©gr√©e √† l‚Äô√©cosyst√®me                     |
| Gouvernance & s√©curit√© | Personnalisable, effort manuel            | Standards cloud, IAM int√©gr√©s               |
| Scalabilit√©            | Exige expertise technique                 | Native, autoscaling int√©gr√©                 |

### Recommandations

* Favoriser l‚Äôopen-source pour les startups tech, √©quipes R\&D ou cas sp√©cifiques tr√®s personnalis√©s.
* Favoriser les cloud providers pour les projets √† fort volume, √©quipes r√©duites ou besoin de time-to-market rapide.

---

